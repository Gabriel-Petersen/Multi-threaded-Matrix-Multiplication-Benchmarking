# Multi-threaded Matrix Multiplication Benchmarking

Este projeto explora diferentes t√©cnicas de otimiza√ß√£o de performance em CPU para a multiplica√ß√£o de matrizes quadradas ($C = A \times B$), um dos pilares da computa√ß√£o de alto desempenho (HPC). O objetivo √© demonstrar como o **layout de mem√≥ria**, a **hierarquia de cache** e o **paralelismo multi-core** impactam drasticamente o tempo de execu√ß√£o.

## üöÄ Resultados (N=7500)

O benchmark abaixo reflete os tempos obtidos em uma matriz de $7500 \times 7500$ (ponto flutuante de precis√£o dupla), comparando a implementa√ß√£o ing√™nua com m√©todos otimizados.

| M√©todo | Tempo (ms) | Speedup | Observa√ß√£o |
| :--- | :---: | :---: | :--- |
| **Trivial** | 2.368.997 | 1.0x | Algoritmo base $O(n^3)$ com Cache Misses constantes. |
| **Transposed Trivial** | 300.015 | 7.9x | Melhora a localidade espacial ao ler B sequencialmente. |
| **Blocking (Tiling)** | 109.107 | 21.7x | Maximiza a localidade temporal mantendo blocos no Cache L1/L2. |
| **Parallel** | 71.064 | 33.3x | Divis√£o de carga entre m√∫ltiplos n√∫cleos via `std::thread`. |
| **Transposed Parallel** | **68.489** | **34.5x** | O estado da arte: Cache-friendly + Multi-core. |

## üõ†Ô∏è Implementa√ß√µes

### 1. Trivial (Baseline)
A implementa√ß√£o cl√°ssica com tr√™s loops aninhados ($i, j, k$). O principal gargalo aqui √© o acesso por colunas na Matriz B. Como matrizes s√£o armazenadas em *Row-Major* (linha ap√≥s linha), saltar entre colunas quebra o fluxo do cache, for√ßando a CPU a buscar dados diretamente na RAM.

### 2. Transposi√ß√£o (Spatial Locality)
Ao transpor a Matriz B para uma matriz auxiliar $T$ ($T[j][k] = B[k][j]$), transformamos acessos por coluna em acessos por linha. Isso permite que o **Hardware Prefetcher** da CPU antecipe os dados e carregue linhas inteiras para o cache L1 antes de serem necess√°rias.

### 3. Blocking / Tiling (Temporal Locality)
Divide as matrizes em pequenos blocos (Tiles) que cabem inteiros nos caches de n√≠veis superiores (L1/L2). Esta t√©cnica garante que um dado carregado seja reutilizado o m√°ximo de vezes poss√≠vel antes de ser descartado da hierarquia de mem√≥ria.

### 4. Multithreading
Utiliza `std::thread::hardware_concurrency()` para distribuir o processamento das linhas de forma independente entre os n√∫cleos da CPU. A implementa√ß√£o evita o *False Sharing* e o custo excessivo de cria√ß√£o de threads ao instanci√°-las apenas uma vez no in√≠cio do c√°lculo.

## üìà An√°lise de Performance
Os testes demonstram o fen√¥meno do **Memory Wall**. Em matrizes de grande escala ($N=7500$), a computa√ß√£o bruta deixa de ser o gargalo, e a efici√™ncia passa a depender quase exclusivamente da largura de banda da mem√≥ria e do gerenciamento inteligente do cache. A combina√ß√£o de **Transposi√ß√£o + Paralelismo** reduziu o tempo de execu√ß√£o de quase **40 minutos** para apenas **68 segundos**.

![Performance Graph](benchmarks/performance_analysis.png)

## üíª Como Executar

### Pr√©-requisitos
* Compilador G++ (suporte a C++20).
* Python 3 e bibliotecas `pandas` e `matplotlib` (para os gr√°ficos).

### Compila√ß√£o (Linux/GCC/MinGW)
```bash
g++ -O3 -Iinclude src/big_matrix.cpp src/main.cpp -o matrix_bench -lpthread
```
*Nota: A flag `-O3` √© fundamental para permitir que o compilador realize a vetoriza√ß√£o (SIMD) autom√°tica das opera√ß√µes.*
### Gerando Gr√°ficos
python: benchmarks/plot_results.py
